{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3439aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.10.3\n",
      "  latest version: 4.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - beautifulsoup4\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    beautifulsoup4-4.10.0      |     pyha770c72_0          77 KB  conda-forge\n",
      "    certifi-2021.10.8          |   py39hf3d152e_1         145 KB  conda-forge\n",
      "    soupsieve-2.3.1            |     pyhd8ed1ab_0          33 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         255 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  beautifulsoup4     conda-forge/noarch::beautifulsoup4-4.10.0-pyha770c72_0\n",
      "  soupsieve          conda-forge/noarch::soupsieve-2.3.1-pyhd8ed1ab_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi                          2021.10.8-py39hf3d152e_0 --> 2021.10.8-py39hf3d152e_1\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "certifi-2021.10.8    | 145 KB    | ##################################### | 100% \n",
      "soupsieve-2.3.1      | 33 KB     | ##################################### | 100% \n",
      "beautifulsoup4-4.10. | 77 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d3f12a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d5babdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('SMSSpamCollection', sep=\"\t\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b621e23",
   "metadata": {},
   "source": [
    "## Part 1: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56655c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  1\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d7876cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                       1\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dbcfde",
   "metadata": {},
   "source": [
    "We are going to maintain duplicates.  As we see here, there are 30 'Sorry, I'll call later.' This means duplicates may be informative to our model as they can come from non-spam automated response messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d17f46",
   "metadata": {},
   "source": [
    "#### Change to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29068af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data[1]\n",
    "text_lowercase = text.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037064ae",
   "metadata": {},
   "source": [
    "#### Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03b6ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def remove_punctuation(document):\n",
    "    no_punct = ''.join([character for character in document if character not in punctuation])\n",
    "    return no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a8e111b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_no_punct  = text_lowercase.apply(remove_punctuation)\n",
    "text_no_punct[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe29a0b8",
   "metadata": {},
   "source": [
    "#### Remove Digits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b1b4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_digit(document): \n",
    "    \n",
    "    no_digit = ''.join([character for character in document if not character.isdigit()])\n",
    "              \n",
    "    return no_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "126b8c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_no_digit = text_no_punct.apply(remove_digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c22846",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "051eca35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /opt/conda/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "447d7c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [go, until, jurong, point, crazy, available, o...\n",
       "1                       [ok, lar, joking, wif, u, oni]\n",
       "2    [free, entry, in, a, wkly, comp, to, win, fa, ...\n",
       "3    [u, dun, say, so, early, hor, u, c, already, t...\n",
       "4    [nah, i, dont, think, he, goes, to, usf, he, l...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text_tokenized = text_no_digit.apply(word_tokenize)\n",
    "text_tokenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81936451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /opt/conda/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ce20697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(document):\n",
    "    \n",
    "    words = [word for word in document if not word in stop_words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f3de909",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_no_stop = text_tokenized.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d405aab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_no_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23195aee",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "808efcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def stemmer(document):\n",
    "    \n",
    "    stemmed_document = [porter.stem(word) for word in document]\n",
    "    \n",
    "    return stemmed_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a39ca1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_stemmed = text_no_stop.apply(stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb35384",
   "metadata": {},
   "source": [
    "#### Detokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3c2b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "text_detokenized = text_stemmed.apply(TreebankWordDetokenizer().detokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16deb4b3",
   "metadata": {},
   "source": [
    "#### Document-term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f72a516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "countvec = CountVectorizer()\n",
    "\n",
    "sparse_dtm = countvec.fit_transform(text_detokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d87c549f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "call         657\n",
       "im           467\n",
       "go           454\n",
       "get          448\n",
       "ur           390\n",
       "            ... \n",
       "enough        29\n",
       "await         28\n",
       "detail        28\n",
       "afternoon     28\n",
       "tv            28\n",
       "Length: 336, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.5% of the posts or more \n",
    "\n",
    "countvec2 = CountVectorizer(min_df=0.005)\n",
    "sparse_dtm2 = countvec2.fit_transform(text_detokenized)\n",
    "\n",
    "dtm2 = pd.DataFrame(sparse_dtm2.toarray(), columns=countvec2.get_feature_names(), index=data.index)\n",
    "dtm2.sum().sort_values(ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0870dbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "call      657\n",
       "im        467\n",
       "go        454\n",
       "get       448\n",
       "ur        390\n",
       "         ... \n",
       "cours      14\n",
       "scream     14\n",
       "comput     14\n",
       "whole      14\n",
       "jay        14\n",
       "Length: 610, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, let's try with 0.25% of the posts or more\n",
    "\n",
    "countvec3 = CountVectorizer(min_df=0.0025)\n",
    "sparse_dtm3 = countvec3.fit_transform(text_detokenized)\n",
    "\n",
    "dtm3 = pd.DataFrame(sparse_dtm3.toarray(), columns=countvec3.get_feature_names(), index=data.index)\n",
    "dtm3.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e3e598",
   "metadata": {},
   "source": [
    "Compared to Homework 5, the quantity of terms in the DTM is comparable under much smaller values of min_df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15e0bf9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ham\n",
       "1        ham\n",
       "2       spam\n",
       "3        ham\n",
       "4        ham\n",
       "        ... \n",
       "5567    spam\n",
       "5568     ham\n",
       "5569     ham\n",
       "5570     ham\n",
       "5571     ham\n",
       "Name: 0, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c2a8a9",
   "metadata": {},
   "source": [
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0f62040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a 70 - 30 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dtm2, data[0], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "626b179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X_train) == len(y_train)\n",
    "assert len(X_test) == len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71beb8b8",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb835a3",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a47c328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=8, min_samples_leaf=5, n_estimators=500,\n",
       "                       random_state=88)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(max_features=8, min_samples_leaf=5, n_estimators=500, random_state=88)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a1ddb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[1447    1]\n",
      " [  57  167]]\n",
      "\n",
      "Accuracy: 0.965311004784689\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix: \\n\", cm)\n",
    "print (\"\\nAccuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97128a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
